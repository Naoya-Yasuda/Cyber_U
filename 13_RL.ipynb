{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第13回演習「強化学習」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この演習では、報酬に基づいて行動する強化学習の方法を習得します。<br />\n",
    "グレイの背景のプログラムは上から順に、1つずつ実行していきましょう。<br />\n",
    "<img src=\"http://pfe.p.cyber-u.ac.jp/img/Python/Week13/rat.png\" style=\"width:200px\">\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) プログラム冒頭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "{0: {0: [1, 0], 1: [0, 0]}, 1: {0: [0, 0], 1: [1, 1]}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "乱数発生器 = np.random.RandomState(9) # 再現性を担保するため\n",
    "試行の中のステップ数 = 10\n",
    "最大の試行エピソード数 = 100\n",
    "これだけ1エピソードで報酬を得たら終了 = 9 # 1エピソードで得られる最大の報酬に達したら打ち切る\n",
    "Qテーブル = np.array([[0.0, 0.0],[0.0, 0.0]]) # intにしたくないので 0.0 とする\n",
    "\n",
    "状態遷移図 = {0:{},1:{}} # Pythonの2次元ディクショナリ\n",
    "状態遷移図[0][0]=[1,0]; # 電源状態0(オフ)で行動0(電源ボタン押す)の時、電源状態1(オン)に遷移し報酬0\n",
    "状態遷移図[0][1]=[0,0]; # 電源状態0(オフ)で行動1(えさボタン押す)の時、電源状態0(オフ)のままで報酬0\n",
    "状態遷移図[1][0]=[0,0]; # 電源状態1(オン)で行動0(電源ボタン押す)の時、電源状態0(オフ)に遷移し報酬0\n",
    "状態遷移図[1][1]=[1,1]; # 電源状態1(オン)で行動1(えさボタン押す)の時、電源状態1(オン)のままで報酬1\n",
    "\n",
    "print(Qテーブル)\n",
    "print(状態遷移図)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Qテーブルの中身を表示する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 0.0000000\n"
     ]
    }
   ],
   "source": [
    "def Qテーブルの中身を表示(Qテーブル):\n",
    "    行数 = Qテーブル.shape[0]\n",
    "    列数 = Qテーブル.shape[1]    \n",
    "    for 行 in range(行数):\n",
    "        for 列 in range(列数):\n",
    "            print(\"Q(%d,%d): %.7f\" % (行,列,Qテーブル[行][列]))\n",
    "\n",
    "Qテーブルの中身を表示(Qテーブル)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題1)\n",
    "<span style=\"background-color:#FFFF99\">\n",
    "Qテーブルの中身を何らかの2×2行列に書き換えて、<br />\n",
    "再度「Qテーブルの中身を表示」関数の動作確認をしましょう。<br />\n",
    "その後、忘れずにQテーブルの中身を元に戻してください。\n",
    "    </span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 念のため、Qテーブルの中身を変えてもう一度動作確認\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) QテーブルからQ値最大の行動を選ぶ関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "def QテーブルからQ値最大の行動を選ぶ(Qテーブル,この電源状態):\n",
    "    最大値 = np.max(Qテーブル[この電源状態])\n",
    "    最大値の場所 = [] # 最大が複数あったら全て返させる。そのための配列。\n",
    "    for i in range(len(Qテーブル[この電源状態])):\n",
    "        if 最大値 == Qテーブル[この電源状態][i]:\n",
    "            最大値の場所.append(i)\n",
    "    return 最大値の場所\n",
    "\n",
    "print(QテーブルからQ値最大の行動を選ぶ(Qテーブル,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題2)\n",
    "<span style=\"background-color:#FFFF99\">\n",
    "Qテーブルの中身を何らかの2×2行列に書き換えて、<br />\n",
    "再度「QテーブルからQ値最大の行動を選ぶ関数」の動作確認をしましょう。<br />\n",
    "その後、忘れずにQテーブルの中身を元に戻してください。\n",
    "    </span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) ε-グリーディ法で次の行動を決定する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε: 0.5\n",
      "乱数: 0.010374153885699955\n",
      "ランダムに選びました\n",
      "次の行動: 0\n"
     ]
    }
   ],
   "source": [
    "def εグリーディ法で次の行動を決定(この電源状態, 試行したエピソード数):\n",
    "    # ここはεグリーディ法の改良版\n",
    "    ランダム行動の選択率ε = 0.5*(1/(試行したエピソード数+1)) # 試行が増えるたびに、最適な行動を選びやすくなる\n",
    "    print(\"ε:\",ランダム行動の選択率ε) # デバッグ用出力\n",
    "    乱数_0から1まで = 乱数発生器.uniform(0, 1)\n",
    "    print(\"乱数:\",乱数_0から1まで)\n",
    "    if ランダム行動の選択率ε <= 乱数_0から1まで: # 乱数がε以上なら、QテーブルからQ値最大の行動を選ぶ\n",
    "        選んだ行動 = QテーブルからQ値最大の行動を選ぶ(Qテーブル,この電源状態)\n",
    "        print(\"Q値最大の行動:\",選んだ行動)\n",
    "        次の行動 = 乱数発生器.choice(選んだ行動) # Q値最大の行動は複数あり得るので、その時は複数からランダム\n",
    "        print(\"Q値最大の行動を選びました\")\n",
    "    else: # 乱数の値がイプシロンより小さければ、Qテーブルは見ずに「次の行動」をランダムに選ぶ\n",
    "        次の行動 = 乱数発生器.choice([0, 1]) # 0か1か\n",
    "        print(\"ランダムに選びました\")\n",
    "    return 次の行動\n",
    "\n",
    "# 電源オフ、エピソード番号0の時の次の行動を出力\n",
    "print(\"次の行動:\",εグリーディ法で次の行動を決定(0, 0)) \n",
    "# ↑ 出力結果が0なら次の行動は「電源ボタンを押す」、1なら「えさボタンを押す」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題3)\n",
    "<span style=\"background-color:#FFFF99\">\n",
    "試行したエピソード数が0の時は「ランダム行動の選択率ε」は0.5でした。<br />\n",
    "試行したエピソード数が5の時には「ランダム行動の選択率ε」はいくつになるでしょうか?\n",
    "    </span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε: 0.08333333333333333\n",
      "乱数: 0.4991303644759453\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "次の行動: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"次の行動:\",εグリーディ法で次の行動を決定(0, 5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Qテーブルを更新する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 0.0000000\n"
     ]
    }
   ],
   "source": [
    "def Qテーブルを更新(Qテーブル, 電源状態, 行動, 報酬, 次の電源状態):\n",
    "    割引率γ = 0.9\n",
    "    学習率α = 0.5\n",
    "    next_maxQ=max(Qテーブル[次の電源状態])\n",
    "    Qテーブル[電源状態,行動] = (1-学習率α)*Qテーブル[電源状態,行動]+学習率α*(報酬+割引率γ*next_maxQ)\n",
    "    return Qテーブル\n",
    "\n",
    "# 「電源オフの時に電源ボタンを押し、報酬は0で、次の電源状態はオンになった」時のQテーブル更新\n",
    "Qテーブル = Qテーブルを更新(Qテーブル, 0, 0, 0, 1)\n",
    "Qテーブルの中身を表示(Qテーブル)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題4)\n",
    "<span style=\"background-color:#FFFF99\">\n",
    "「電源オンの時にえさボタンを押し、報酬は1で、次の電源状態はオフになった」時の<br />\n",
    " Qテーブル更新をテストしてみましょう。Q(1,1)は 0.5000000 になるでしょうか?<br />\n",
    " テストの後、忘れずにQテーブルの中身を [[0.0, 0.0],[0.0, 0.0]] に戻してください。\n",
    " </span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 0.5000000\n"
     ]
    }
   ],
   "source": [
    "# 「電源オンの時にえさボタンを押し、報酬は1で、次の電源状態はオフになった」時のQテーブル更新\n",
    "Qテーブル = Qテーブルを更新(Qテーブル, 1, 1, 1, 0)\n",
    "Qテーブルの中身を表示(Qテーブル)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) メインの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε: 0.5\n",
      "乱数: 0.010374153885699955\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.4991303644759453\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.13382952895927658\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.01332201226471863\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.41850818051045247\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.13861327680989832\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.3454986400504001\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.315708867300742\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.9509640316267165\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.5\n",
      "乱数: 0.9679040811889423\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "試行したエピソードの数 1 このエピソードでの報酬 0\n",
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 0.0000000\n",
      "ε: 0.25\n",
      "乱数: 0.5727598155694092\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.13600697865261857\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.5478377830464816\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.9433069034403351\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.6944386777644582\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.6395682354693746\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.9405244095266561\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.8342958389472905\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.1696362575837671\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "ε: 0.25\n",
      "乱数: 0.06766956258950685\n",
      "ランダムに選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "試行したエピソードの数 2 このエピソードでの報酬 0\n",
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 0.0000000\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.6495404631604762\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.9252234546158165\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.18554168693446071\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.5817513903483811\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.9062772769235077\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.5802602123238292\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.46353471398405754\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.43488873166055764\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.4779740135383469\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.16666666666666666\n",
      "乱数: 0.43555546476634577\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 3 このエピソードでの報酬 3\n",
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 1.4262500\n",
      "ε: 0.125\n",
      "乱数: 0.8704082964265311\n",
      "Q値最大の行動: [0, 1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.125\n",
      "乱数: 0.9297378934001482\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.125\n",
      "乱数: 0.3927811287606445\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.125\n",
      "乱数: 0.289339452424646\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.125\n",
      "乱数: 0.31675248622488084\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.125\n",
      "乱数: 0.986894381397342\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.125\n",
      "乱数: 0.04285167633037257\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.125\n",
      "乱数: 0.461697662470697\n",
      "Q値最大の行動: [0]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.125\n",
      "乱数: 0.053059424485393025\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.125\n",
      "乱数: 0.6737143186444894\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 4 このエピソードでの報酬 7\n",
      "Q(0,0): 1.8355143\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.2888156\n",
      "Q(1,1): 4.0126306\n",
      "ε: 0.1\n",
      "乱数: 0.2396081670712522\n",
      "Q値最大の行動: [0]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.1\n",
      "乱数: 0.1774603513077352\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.1\n",
      "乱数: 0.12835627152576068\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.1\n",
      "乱数: 0.07008555794445381\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.1\n",
      "乱数: 0.4844984551528021\n",
      "Q値最大の行動: [0]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.1\n",
      "乱数: 0.6977363851237776\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.1\n",
      "乱数: 0.801156431695686\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.1\n",
      "乱数: 0.2667743770719413\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.1\n",
      "乱数: 0.9094762092582502\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.1\n",
      "乱数: 0.022866949969676864\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 5 このエピソードでの報酬 7\n",
      "Q(0,0): 3.4301001\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 1.3699562\n",
      "Q(1,1): 5.8187966\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.9032663941356042\n",
      "Q値最大の行動: [0]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.8042420323402079\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.004563849002959475\n",
      "ランダムに選びました\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.49813961036179266\n",
      "Q値最大の行動: [0]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.41434632479962163\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.21425596288493742\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.2166397127268621\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.2323071272464986\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.7290856206264126\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.08333333333333333\n",
      "乱数: 0.4159186670147922\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 6 このエピソードでの報酬 7\n",
      "Q(0,0): 4.8792898\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 2.6350570\n",
      "Q(1,1): 7.0801098\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.5838981780137995\n",
      "Q値最大の行動: [0]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.4943366051327067\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.4300468142111865\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.7347658170361696\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.5562164868036489\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.3026306416600065\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.970798194813456\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.22484261212330414\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.13876915695467273\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "ε: 0.07142857142857142\n",
      "乱数: 0.6149324753622187\n",
      "Q値最大の行動: [1]\n",
      "Q値最大の行動を選びました\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 7 このエピソードでの報酬 9\n",
      "Q(0,0): 5.6256943\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 2.6350570\n",
      "Q(1,1): 8.1597409\n"
     ]
    }
   ],
   "source": [
    "乱数発生器 = np.random.RandomState(9) # 何度も乱数を発生させたので、改めて種を入れ直す\n",
    "Qテーブル = np.array([[0.0, 0.0],[0.0, 0.0]]) # Qテーブルも戻す\n",
    "\n",
    "##### これよりメインの処理 #####\n",
    "for 試行エピソード番号 in range(最大の試行エピソード数): # 最大が100なら、rangeは0から99\n",
    "    電源状態 = 0\n",
    "    このエピソードでの報酬 = 0\n",
    " \n",
    "    for ステップ in range(試行の中のステップ数):  # 試行の中での繰り返し\n",
    "        行動 = εグリーディ法で次の行動を決定(電源状態, 試行エピソード番号) \n",
    "        次の電源状態, 報酬 = 状態遷移図[電源状態][行動]\n",
    "        print(\"電源状態:\",電源状態,\"取った行動:\", 行動, \"得た報酬:\",報酬)\n",
    "        このエピソードでの報酬 = このエピソードでの報酬 + 報酬  # 得た報酬を足し込む\n",
    "        Qテーブル = Qテーブルを更新(Qテーブル, 電源状態, 行動, 報酬, 次の電源状態)\n",
    "        電源状態 = 次の電源状態\n",
    "\n",
    "    print('試行したエピソードの数',試行エピソード番号+1,'このエピソードでの報酬',このエピソードでの報酬)\n",
    "    Qテーブルの中身を表示(Qテーブル)\n",
    "    if このエピソードでの報酬 >= これだけ1エピソードで報酬を得たら終了:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) これまでのプログラムをまとめたもの<br />(途中のデバッグ用出力は省く)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "試行したエピソードの数 1 このエピソードでの報酬 0\n",
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 0.0000000\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 1 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "試行したエピソードの数 2 このエピソードでの報酬 0\n",
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 0.0000000\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 3 このエピソードでの報酬 3\n",
      "Q(0,0): 0.0000000\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.0000000\n",
      "Q(1,1): 1.4262500\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 4 このエピソードでの報酬 7\n",
      "Q(0,0): 1.8355143\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 0.2888156\n",
      "Q(1,1): 4.0126306\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 5 このエピソードでの報酬 7\n",
      "Q(0,0): 3.4301001\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 1.3699562\n",
      "Q(1,1): 5.8187966\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 0 得た報酬: 0\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 6 このエピソードでの報酬 7\n",
      "Q(0,0): 4.8792898\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 2.6350570\n",
      "Q(1,1): 7.0801098\n",
      "電源状態: 0 取った行動: 0 得た報酬: 0\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "電源状態: 1 取った行動: 1 得た報酬: 1\n",
      "試行したエピソードの数 7 このエピソードでの報酬 9\n",
      "Q(0,0): 5.6256943\n",
      "Q(0,1): 0.0000000\n",
      "Q(1,0): 2.6350570\n",
      "Q(1,1): 8.1597409\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "乱数発生器 = np.random.RandomState(9) # 再現性を担保するため\n",
    "試行の中のステップ数 = 10\n",
    "最大の試行エピソード数 = 100\n",
    "これだけ1エピソードで報酬を得たら終了 = 9 # 1エピソードで得られる最大の報酬に達したら打ち切る\n",
    "Qテーブル = np.array([[0.0, 0.0],[0.0, 0.0]]) # intにしたくないので 0.0 とする\n",
    "\n",
    "状態遷移図 = {0:{},1:{}} # Pythonの2次元ディクショナリ\n",
    "状態遷移図[0][0]=[1,0]; # 電源状態0(オフ)で行動0(電源ボタン押す)の時、電源状態1(オン)に遷移し報酬0\n",
    "状態遷移図[0][1]=[0,0]; # 電源状態0(オフ)で行動1(えさボタン押す)の時、電源状態0(オフ)のままで報酬0\n",
    "状態遷移図[1][0]=[0,0]; # 電源状態1(オン)で行動0(電源ボタン押す)の時、電源状態0(オフ)に遷移し報酬0\n",
    "状態遷移図[1][1]=[1,1]; # 電源状態1(オン)で行動1(えさボタン押す)の時、電源状態1(オン)のままで報酬1\n",
    "\n",
    "def Qテーブルの中身を表示(Qテーブル):\n",
    "    行数 = Qテーブル.shape[0]\n",
    "    列数 = Qテーブル.shape[1]    \n",
    "    for 行 in range(行数):\n",
    "        for 列 in range(列数):\n",
    "            print(\"Q(%d,%d): %.7f\" % (行,列,Qテーブル[行][列]))\n",
    "\n",
    "def QテーブルからQ値最大の行動を選ぶ(Qテーブル,この電源状態):\n",
    "    最大値 = np.max(Qテーブル[この電源状態])\n",
    "    最大値の場所 = []\n",
    "    for i in range(len(Qテーブル[この電源状態])):\n",
    "        if 最大値 == Qテーブル[この電源状態][i]:\n",
    "            最大値の場所.append(i)\n",
    "    return 最大値の場所\n",
    "            \n",
    "def εグリーディ法で次の行動を決定(この電源状態, 試行したエピソード数):\n",
    "    # ここはεグリーディ法の改良版\n",
    "    ランダム行動の選択率ε = 0.5*(1/(試行したエピソード数+1)) # 試行が増えるたびに、最適な行動を選びやすくなる\n",
    "    乱数_0から1まで = 乱数発生器.uniform(0, 1)    \n",
    "    if ランダム行動の選択率ε <= 乱数_0から1まで: # 乱数がε以上なら、QテーブルからQ値最大の行動を選ぶ\n",
    "        選んだ行動 = QテーブルからQ値最大の行動を選ぶ(Qテーブル,この電源状態)        \n",
    "        次の行動 = 乱数発生器.choice(選んだ行動) # Q値最大の行動は複数あり得るので、その時は複数からランダム        \n",
    "    else: # 乱数の値がイプシロンより小さければ、Qテーブルは見ずに「次の行動」をランダムに選ぶ\n",
    "        次の行動 = 乱数発生器.choice([0, 1]) # 0か1か        \n",
    "    return 次の行動\n",
    "\n",
    "def Qテーブルを更新(Qテーブル, 電源状態, 行動, 報酬, 次の電源状態):\n",
    "    割引率γ = 0.9\n",
    "    学習率α = 0.5\n",
    "    next_maxQ=max(Qテーブル[次の電源状態])\n",
    "    Qテーブル[電源状態,行動] = (1-学習率α)*Qテーブル[電源状態,行動]+学習率α*(報酬+割引率γ*next_maxQ)\n",
    "    return Qテーブル\n",
    "\n",
    "##### これよりメインの処理 #####\n",
    "このエピソードでの報酬リスト = []\n",
    "最後のエピソード = 0\n",
    "for 試行エピソード番号 in range(最大の試行エピソード数): # 最大が100なら、rangeは0から99\n",
    "    電源状態 = 0\n",
    "    このエピソードでの報酬 = 0\n",
    "    for ステップ in range(試行の中のステップ数):  # 試行の中での繰り返し\n",
    "        行動 = εグリーディ法で次の行動を決定(電源状態, 試行エピソード番号) \n",
    "        次の電源状態, 報酬 = 状態遷移図[電源状態][行動]\n",
    "        print(\"電源状態:\",電源状態,\"取った行動:\", 行動, \"得た報酬:\",報酬)\n",
    "        このエピソードでの報酬 = このエピソードでの報酬 + 報酬  # 得た報酬を足し込む\n",
    "        Qテーブル = Qテーブルを更新(Qテーブル, 電源状態, 行動, 報酬, 次の電源状態)\n",
    "        電源状態 = 次の電源状態\n",
    "\n",
    "    このエピソードでの報酬リスト.append(このエピソードでの報酬)\n",
    "    print('試行したエピソードの数',試行エピソード番号+1,'このエピソードでの報酬',このエピソードでの報酬)    \n",
    "    Qテーブルの中身を表示(Qテーブル)\n",
    "    if このエピソードでの報酬 >= これだけ1エピソードで報酬を得たら終了:\n",
    "        最後のエピソード = 試行エピソード番号\n",
    "        break\n",
    "plt.figure()\n",
    "plt.plot([i+1 for i in range(len(このエピソードでの報酬リスト))], このエピソードでの報酬リスト)\n",
    "y_min, y_max = 0, 9\n",
    "# y軸の目盛りを1毎に設定\n",
    "plt.yticks(range(y_min, y_max + 1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題5)\n",
    "<span style=\"background-color:#FFFF99\">\n",
    "上記のプログラム #6 を改造し「試行したエピソードが増えるにつれて、<br />\n",
    "    エピソード毎の報酬が変化していく様子」を\n",
    "図示しましょう。\n",
    " </span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第13回第3章の演習はここまでです。引き続き、第4章の講義を見ましょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
