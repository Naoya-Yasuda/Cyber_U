{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwy0fxQIiqw_"
      },
      "source": [
        "**第1章**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mff0FYYvipqK",
        "outputId": "9252a3a7-a84a-43f4-8886-9ebc01130f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.59040716\n",
            "Iteration 2, loss = 0.42689430\n",
            "Iteration 3, loss = 0.38818861\n",
            "Iteration 4, loss = 0.36907432\n",
            "Iteration 5, loss = 0.35097784\n",
            "Iteration 6, loss = 0.33207634\n",
            "Iteration 7, loss = 0.32134920\n",
            "Iteration 8, loss = 0.30733297\n",
            "Iteration 9, loss = 0.30010049\n",
            "Iteration 10, loss = 0.29097071\n",
            "Iteration 11, loss = 0.28245670\n",
            "Iteration 12, loss = 0.27724702\n",
            "Iteration 13, loss = 0.27187276\n",
            "Iteration 14, loss = 0.26169707\n",
            "Iteration 15, loss = 0.25824257\n",
            "Iteration 16, loss = 0.25525870\n",
            "Iteration 17, loss = 0.24733403\n",
            "Iteration 18, loss = 0.24254494\n",
            "Iteration 19, loss = 0.23931808\n",
            "Iteration 20, loss = 0.23533019\n",
            "Iteration 21, loss = 0.22769297\n",
            "Iteration 22, loss = 0.22728435\n",
            "Iteration 23, loss = 0.22057516\n",
            "Iteration 24, loss = 0.21832263\n",
            "Iteration 25, loss = 0.21219030\n",
            "Iteration 26, loss = 0.20948274\n",
            "Iteration 27, loss = 0.20592165\n",
            "Iteration 28, loss = 0.20364800\n",
            "Iteration 29, loss = 0.20028596\n",
            "Iteration 30, loss = 0.19827154\n",
            "Iteration 31, loss = 0.19461946\n",
            "Iteration 32, loss = 0.19325997\n",
            "Iteration 33, loss = 0.18860748\n",
            "Iteration 34, loss = 0.18599427\n",
            "Iteration 35, loss = 0.18360514\n",
            "Iteration 36, loss = 0.17937962\n",
            "Iteration 37, loss = 0.17952043\n",
            "Iteration 38, loss = 0.17785604\n",
            "Iteration 39, loss = 0.17179249\n",
            "Iteration 40, loss = 0.16817813\n",
            "Iteration 41, loss = 0.16540132\n",
            "Iteration 42, loss = 0.16551021\n",
            "Iteration 43, loss = 0.16449938\n",
            "Iteration 44, loss = 0.15969416\n",
            "Iteration 45, loss = 0.15710399\n",
            "Iteration 46, loss = 0.15577538\n",
            "Iteration 47, loss = 0.15393685\n",
            "Iteration 48, loss = 0.15149150\n",
            "Iteration 49, loss = 0.14868145\n",
            "Iteration 50, loss = 0.14535043\n",
            "Iteration 51, loss = 0.14712576\n",
            "Iteration 52, loss = 0.14297672\n",
            "Iteration 53, loss = 0.14114264\n",
            "Iteration 54, loss = 0.13764388\n",
            "Iteration 55, loss = 0.13751898\n",
            "Iteration 56, loss = 0.13473331\n",
            "Iteration 57, loss = 0.13619817\n",
            "Iteration 58, loss = 0.12739545\n",
            "Iteration 59, loss = 0.12916211\n",
            "Iteration 60, loss = 0.12847923\n",
            "Iteration 61, loss = 0.12608611\n",
            "Iteration 62, loss = 0.12448406\n",
            "Iteration 63, loss = 0.12300856\n",
            "Iteration 64, loss = 0.12284346\n",
            "Iteration 65, loss = 0.11854751\n",
            "Iteration 66, loss = 0.11753008\n",
            "Iteration 67, loss = 0.11860187\n",
            "Iteration 68, loss = 0.11499782\n",
            "Iteration 69, loss = 0.11449038\n",
            "Iteration 70, loss = 0.11281157\n",
            "Iteration 71, loss = 0.11038738\n",
            "Iteration 72, loss = 0.10801807\n",
            "Iteration 73, loss = 0.10909754\n",
            "Iteration 74, loss = 0.10553253\n",
            "Iteration 75, loss = 0.10511785\n",
            "Iteration 76, loss = 0.10431434\n",
            "Iteration 77, loss = 0.10204025\n",
            "Iteration 78, loss = 0.10123969\n",
            "Iteration 79, loss = 0.09950168\n",
            "Iteration 80, loss = 0.09916370\n",
            "Iteration 81, loss = 0.10102330\n",
            "Iteration 82, loss = 0.09949023\n",
            "Iteration 83, loss = 0.09590501\n",
            "Iteration 84, loss = 0.09346020\n",
            "Iteration 85, loss = 0.09336164\n",
            "Iteration 86, loss = 0.09516642\n",
            "Iteration 87, loss = 0.08728176\n",
            "Iteration 88, loss = 0.08928788\n",
            "Iteration 89, loss = 0.08932665\n",
            "Iteration 90, loss = 0.09146768\n",
            "Iteration 91, loss = 0.08515827\n",
            "Iteration 92, loss = 0.08376456\n",
            "Iteration 93, loss = 0.08549916\n",
            "Iteration 94, loss = 0.08471793\n",
            "Iteration 95, loss = 0.08357978\n",
            "Iteration 96, loss = 0.08227675\n",
            "Iteration 97, loss = 0.08121061\n",
            "Iteration 98, loss = 0.07915399\n",
            "Iteration 99, loss = 0.08013043\n",
            "Iteration 100, loss = 0.07833247\n",
            "Iteration 101, loss = 0.07732909\n",
            "Iteration 102, loss = 0.07749338\n",
            "Iteration 103, loss = 0.07784661\n",
            "Iteration 104, loss = 0.07557887\n",
            "Iteration 105, loss = 0.07421733\n",
            "Iteration 106, loss = 0.07209376\n",
            "Iteration 107, loss = 0.07517464\n",
            "Iteration 108, loss = 0.07056075\n",
            "Iteration 109, loss = 0.07086512\n",
            "Iteration 110, loss = 0.07056623\n",
            "Iteration 111, loss = 0.06882393\n",
            "Iteration 112, loss = 0.06758195\n",
            "Iteration 113, loss = 0.06491833\n",
            "Iteration 114, loss = 0.06558470\n",
            "Iteration 115, loss = 0.06629165\n",
            "Iteration 116, loss = 0.06615808\n",
            "Iteration 117, loss = 0.06501117\n",
            "Iteration 118, loss = 0.06566697\n",
            "Iteration 119, loss = 0.06584790\n",
            "Iteration 120, loss = 0.06369133\n",
            "Iteration 121, loss = 0.06278252\n",
            "Iteration 122, loss = 0.06295487\n",
            "Iteration 123, loss = 0.05854024\n",
            "Iteration 124, loss = 0.06264217\n",
            "Iteration 125, loss = 0.05875893\n",
            "Iteration 126, loss = 0.05568247\n",
            "Iteration 127, loss = 0.05955180\n",
            "Iteration 128, loss = 0.05834109\n",
            "Iteration 129, loss = 0.05280897\n",
            "Iteration 130, loss = 0.05696012\n",
            "Iteration 131, loss = 0.05828682\n",
            "Iteration 132, loss = 0.05851936\n",
            "Iteration 133, loss = 0.05453328\n",
            "Iteration 134, loss = 0.05997928\n",
            "Iteration 135, loss = 0.05231934\n",
            "Iteration 136, loss = 0.05005951\n",
            "Iteration 137, loss = 0.05651599\n",
            "Iteration 138, loss = 0.05131102\n",
            "Iteration 139, loss = 0.05378605\n",
            "Iteration 140, loss = 0.04918230\n",
            "Iteration 141, loss = 0.05066413\n",
            "Iteration 142, loss = 0.05042439\n",
            "Iteration 143, loss = 0.04698922\n",
            "Iteration 144, loss = 0.04986043\n",
            "Iteration 145, loss = 0.04718850\n",
            "Iteration 146, loss = 0.05340750\n",
            "Iteration 147, loss = 0.04769083\n",
            "Iteration 148, loss = 0.04779792\n",
            "Iteration 149, loss = 0.04764901\n",
            "Iteration 150, loss = 0.04588812\n",
            "Iteration 151, loss = 0.04463739\n",
            "Iteration 152, loss = 0.04820888\n",
            "Iteration 153, loss = 0.04435988\n",
            "Iteration 154, loss = 0.04981751\n",
            "Iteration 155, loss = 0.04028879\n",
            "Iteration 156, loss = 0.05160545\n",
            "Iteration 157, loss = 0.04655669\n",
            "Iteration 158, loss = 0.04198687\n",
            "Iteration 159, loss = 0.04252719\n",
            "Iteration 160, loss = 0.04333771\n",
            "Iteration 161, loss = 0.04447022\n",
            "Iteration 162, loss = 0.04303787\n",
            "Iteration 163, loss = 0.04470774\n",
            "Iteration 164, loss = 0.03733912\n",
            "Iteration 165, loss = 0.03993386\n",
            "Iteration 166, loss = 0.04405381\n",
            "Iteration 167, loss = 0.05052495\n",
            "Iteration 168, loss = 0.03875865\n",
            "Iteration 169, loss = 0.03657927\n",
            "Iteration 170, loss = 0.03691388\n",
            "Iteration 171, loss = 0.04480313\n",
            "Iteration 172, loss = 0.04088559\n",
            "Iteration 173, loss = 0.03514016\n",
            "Iteration 174, loss = 0.03699586\n",
            "Iteration 175, loss = 0.04042412\n",
            "Iteration 176, loss = 0.03804305\n",
            "Iteration 177, loss = 0.04026769\n",
            "Iteration 178, loss = 0.03379690\n",
            "Iteration 179, loss = 0.03484885\n",
            "Iteration 180, loss = 0.03642250\n",
            "Iteration 181, loss = 0.03354452\n",
            "Iteration 182, loss = 0.03507759\n",
            "Iteration 183, loss = 0.03763868\n",
            "Iteration 184, loss = 0.03736418\n",
            "Iteration 185, loss = 0.03396285\n",
            "Iteration 186, loss = 0.03188382\n",
            "Iteration 187, loss = 0.03357475\n",
            "Iteration 188, loss = 0.04298694\n",
            "Iteration 189, loss = 0.02859658\n",
            "Iteration 190, loss = 0.03312572\n",
            "Iteration 191, loss = 0.03547521\n",
            "Iteration 192, loss = 0.03614115\n",
            "Iteration 193, loss = 0.03529172\n",
            "Iteration 194, loss = 0.02808222\n",
            "Iteration 195, loss = 0.02900030\n",
            "Iteration 196, loss = 0.03784417\n",
            "Iteration 197, loss = 0.02720012\n",
            "Iteration 198, loss = 0.03991357\n",
            "Iteration 199, loss = 0.03441955\n",
            "Iteration 200, loss = 0.03021903\n",
            "精度: 0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28*28).astype(np.float32) # (2) データを前処理する\n",
        "訓練画像 /= 255 # (2) データを前処理する\n",
        "mlp = MLPClassifier(verbose=True)# (3) モデルを作成する\n",
        "mlp.fit(訓練画像, 訓練ラベル) # (4) モデルを訓練する\n",
        "\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28*28).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "精度 = mlp.score(テスト画像, テストラベル) # (5) モデルを評価する\n",
        "print('精度:', 精度)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIuABBlvMufa",
        "outputId": "0d4e0fb2-04a5-469c-aacf-3e13ad7fe899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 7s 11ms/step - loss: 0.5697 - accuracy: 0.8091 - val_loss: 0.4949 - val_accuracy: 0.8210\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.4118 - accuracy: 0.8574 - val_loss: 0.4349 - val_accuracy: 0.8485\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3750 - accuracy: 0.8673 - val_loss: 0.3981 - val_accuracy: 0.8591\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3499 - accuracy: 0.8753 - val_loss: 0.3974 - val_accuracy: 0.8578\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3351 - accuracy: 0.8798 - val_loss: 0.3660 - val_accuracy: 0.8698\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3145 - accuracy: 0.8871 - val_loss: 0.3743 - val_accuracy: 0.8656\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3046 - accuracy: 0.8892 - val_loss: 0.3626 - val_accuracy: 0.8687\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2932 - accuracy: 0.8924 - val_loss: 0.3449 - val_accuracy: 0.8767\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2859 - accuracy: 0.8952 - val_loss: 0.3804 - val_accuracy: 0.8632\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2759 - accuracy: 0.8993 - val_loss: 0.3809 - val_accuracy: 0.8596\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2699 - accuracy: 0.9008 - val_loss: 0.3442 - val_accuracy: 0.8759\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2590 - accuracy: 0.9046 - val_loss: 0.3438 - val_accuracy: 0.8751\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2537 - accuracy: 0.9067 - val_loss: 0.3341 - val_accuracy: 0.8836\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2474 - accuracy: 0.9097 - val_loss: 0.3369 - val_accuracy: 0.8769\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2428 - accuracy: 0.9115 - val_loss: 0.3545 - val_accuracy: 0.8771\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2401 - accuracy: 0.9112 - val_loss: 0.3489 - val_accuracy: 0.8761\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2294 - accuracy: 0.9149 - val_loss: 0.3338 - val_accuracy: 0.8843\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2244 - accuracy: 0.9180 - val_loss: 0.3395 - val_accuracy: 0.8807\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2204 - accuracy: 0.9188 - val_loss: 0.3260 - val_accuracy: 0.8854\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2150 - accuracy: 0.9201 - val_loss: 0.3466 - val_accuracy: 0.8832\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8832\n",
            "test loss: 0.3465563654899597\n",
            "test acc: 0.8831999897956848\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28*28).astype(np.float32) # (2) データを前処理する\n",
        "訓練画像 /= 255 # (2) データを前処理する\n",
        "訓練ラベル = to_categorical(訓練ラベル, 10) # (3) ラベルをワンホットエンコーディングにする\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28*28).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "テストラベル = to_categorical(テストラベル, 10)\n",
        "\n",
        "model = Sequential() # (4)モデルを作成する\n",
        "model.add(Dense(100, input_shape=(28*28, ), activation='relu'))\n",
        "model.add(Dense(10, activation='softmax')) # 出力層\n",
        "\n",
        "model.summary() # モデルを表示する\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # (5) モデルをコンパイルする\n",
        "              optimizer='adam', # 更新方法\n",
        "              metrics=['accuracy']) # 正答率\n",
        "\n",
        "model.fit(訓練画像, 訓練ラベル, # (6) モデルを訓練する\n",
        "                 batch_size=128, epochs=20, verbose=1,\n",
        "                 validation_data=(テスト画像, テストラベル))\n",
        "\n",
        "score = model.evaluate(テスト画像, テストラベル) # (7) モデルを評価する\n",
        "print('test loss:', score[0]) # 結果の表示\n",
        "print('test acc:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY6OhCxDDP88"
      },
      "source": [
        "**第2章**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA7mL1qgDOyT",
        "outputId": "916589f3-c4ea-4bda-9be9-e94d8ba3503f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5705 - accuracy: 0.8041 - val_loss: 0.4601 - val_accuracy: 0.8399\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4134 - accuracy: 0.8548 - val_loss: 0.4183 - val_accuracy: 0.8521\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3726 - accuracy: 0.8682 - val_loss: 0.3959 - val_accuracy: 0.8607\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3489 - accuracy: 0.8748 - val_loss: 0.3755 - val_accuracy: 0.8686\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3280 - accuracy: 0.8820 - val_loss: 0.3735 - val_accuracy: 0.8690\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3141 - accuracy: 0.8868 - val_loss: 0.3705 - val_accuracy: 0.8658\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2997 - accuracy: 0.8916 - val_loss: 0.3579 - val_accuracy: 0.8705\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2874 - accuracy: 0.8956 - val_loss: 0.3452 - val_accuracy: 0.8767\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.2788 - accuracy: 0.8986 - val_loss: 0.3506 - val_accuracy: 0.8703\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2716 - accuracy: 0.9011 - val_loss: 0.3614 - val_accuracy: 0.8721\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2630 - accuracy: 0.9035 - val_loss: 0.3413 - val_accuracy: 0.8774\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2578 - accuracy: 0.9046 - val_loss: 0.3513 - val_accuracy: 0.8749\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2480 - accuracy: 0.9092 - val_loss: 0.3466 - val_accuracy: 0.8764\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2416 - accuracy: 0.9111 - val_loss: 0.3405 - val_accuracy: 0.8816\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2358 - accuracy: 0.9130 - val_loss: 0.3457 - val_accuracy: 0.8792\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2315 - accuracy: 0.9151 - val_loss: 0.3278 - val_accuracy: 0.8839\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2245 - accuracy: 0.9169 - val_loss: 0.3328 - val_accuracy: 0.8831\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2204 - accuracy: 0.9189 - val_loss: 0.3274 - val_accuracy: 0.8850\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2152 - accuracy: 0.9207 - val_loss: 0.3362 - val_accuracy: 0.8808\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2097 - accuracy: 0.9235 - val_loss: 0.3319 - val_accuracy: 0.8873\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8873\n",
            "test loss: 0.33191439509391785\n",
            "test acc: 0.8873000144958496\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28*28).astype(np.float32) # (2) データを前処理する\n",
        "訓練画像 /= 255 # (2) データを前処理する\n",
        "訓練ラベル = to_categorical(訓練ラベル, 10) # (3) ラベルをワンホットエンコーディングにする\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28*28).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "テストラベル = to_categorical(テストラベル, 10)\n",
        "\n",
        "model = Sequential() # (4)モデルを作成する\n",
        "model.add(Dense(100, input_shape=(28*28, ), activation='relu'))\n",
        "model.add(Dense(10, activation='softmax')) # 出力層\n",
        "\n",
        "model.summary() # モデルを表示する\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # (5) モデルをコンパイルする\n",
        "              optimizer='adam', # 更新方法\n",
        "              metrics=['accuracy']) # 正答率\n",
        "\n",
        "model.fit(訓練画像, 訓練ラベル, # (6) モデルを訓練する\n",
        "                 batch_size=128, epochs=20, verbose=1,\n",
        "                 validation_data=(テスト画像, テストラベル))\n",
        "\n",
        "score = model.evaluate(テスト画像, テストラベル) # (7) モデルを評価する\n",
        "print('test loss:', score[0]) # 結果の表示\n",
        "print('test acc:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvBEADZHQQ0M",
        "outputId": "cdd86a62-ab11-457a-b437-c17f255adc82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89610 (350.04 KB)\n",
            "Trainable params: 89610 (350.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5520 - accuracy: 0.8089 - val_loss: 0.4470 - val_accuracy: 0.8407\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3891 - accuracy: 0.8608 - val_loss: 0.4082 - val_accuracy: 0.8529\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3482 - accuracy: 0.8742 - val_loss: 0.3780 - val_accuracy: 0.8642\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8831 - val_loss: 0.3665 - val_accuracy: 0.8690\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3048 - accuracy: 0.8882 - val_loss: 0.3585 - val_accuracy: 0.8704\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2923 - accuracy: 0.8940 - val_loss: 0.3397 - val_accuracy: 0.8778\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2774 - accuracy: 0.8974 - val_loss: 0.3505 - val_accuracy: 0.8769\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2664 - accuracy: 0.9012 - val_loss: 0.3609 - val_accuracy: 0.8739\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2561 - accuracy: 0.9046 - val_loss: 0.3484 - val_accuracy: 0.8767\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2505 - accuracy: 0.9074 - val_loss: 0.3280 - val_accuracy: 0.8820\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2413 - accuracy: 0.9101 - val_loss: 0.3275 - val_accuracy: 0.8865\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.2316 - accuracy: 0.9144 - val_loss: 0.3350 - val_accuracy: 0.8828\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2258 - accuracy: 0.9162 - val_loss: 0.3310 - val_accuracy: 0.8865\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2202 - accuracy: 0.9180 - val_loss: 0.3298 - val_accuracy: 0.8848\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2120 - accuracy: 0.9203 - val_loss: 0.3396 - val_accuracy: 0.8848\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2054 - accuracy: 0.9232 - val_loss: 0.3419 - val_accuracy: 0.8834\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2012 - accuracy: 0.9253 - val_loss: 0.3519 - val_accuracy: 0.8857\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1960 - accuracy: 0.9266 - val_loss: 0.3391 - val_accuracy: 0.8873\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9263 - val_loss: 0.3537 - val_accuracy: 0.8859\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1851 - accuracy: 0.9307 - val_loss: 0.3668 - val_accuracy: 0.8802\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3668 - accuracy: 0.8802\n",
            "test loss: 0.3668062388896942\n",
            "test acc: 0.8802000284194946\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28*28).astype(np.float32) # (2) データを前処理する\n",
        "訓練画像 /= 255 # （2） データを前処理する\n",
        "訓練ラベル = to_categorical(訓練ラベル, 10) # (3) ラベルをワンホットエンコーディングにする\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28*28).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "テストラベル = to_categorical(テストラベル, 10)\n",
        "\n",
        "model = Sequential() # (4)モデルを作成する\n",
        "model.add(Dense(100, input_shape=(28*28, ), activation='relu'))\n",
        "model.add(Dense(100, activation='relu')) # 2層目\n",
        "model.add(Dense(10, activation='softmax')) # 出力層\n",
        "\n",
        "model.summary() # モデルを表示する\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # (5) モデルをコンパイルする\n",
        "              optimizer='adam', # 更新方法\n",
        "              metrics=['accuracy']) # 正答率\n",
        "\n",
        "model.fit(訓練画像, 訓練ラベル, # (6) モデルを訓練する\n",
        "                 batch_size=128, epochs=20, verbose=1,\n",
        "                 validation_data=(テスト画像, テストラベル))\n",
        "\n",
        "score = model.evaluate(テスト画像, テストラベル) # (7) モデルを評価する\n",
        "print('test loss:', score[0]) # 結果の表示\n",
        "print('test acc:', score[1])\n",
        "\n",
        "model.save('model_weightsNN.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2DF0u_9fDep",
        "outputId": "b26ea9fc-9c49-4f7a-cc3c-ab388573cb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n",
            "[[6.6442751e-10 7.8357973e-11 1.4559112e-10 2.5997614e-11 1.5214693e-10\n",
            "  1.4243347e-18 1.4172203e-08 3.7044685e-15 1.0000000e+00 1.7203960e-12]]\n",
            "予測結果: 8\n",
            "予測結果: バッグ\n"
          ]
        }
      ],
      "source": [
        "! curl -s -O http://matsuda.php.xdomain.jp/pe/bag.jpg\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('model_weightsNN.keras') # 訓練結果の読み込み\n",
        "\n",
        "画像 = cv2.imread('bag.jpg') # 画像ファイルの読み込み\n",
        "画像 = cv2.resize(画像, (28, 28)) # データのリサイズ\n",
        "グレー画像 = cv2.cvtColor(画像, cv2.COLOR_BGR2GRAY) # グレースケール化\n",
        "白黒反転 = cv2.bitwise_not(グレー画像)\n",
        "白黒反転 = np.array(白黒反転, 'float32') # NumPyの配列にする\n",
        "自分の画像 = 白黒反転.reshape(1, 28*28) # 1次元配列に変換\n",
        "自分の画像 /= 255  # 0~1へ\n",
        "\n",
        "予測結果群 = model.predict([自分の画像]) # 予測\n",
        "print(予測結果群)\n",
        "予測結果 = np.argmax(予測結果群)\n",
        "print('予測結果:', 予測結果)\n",
        "\n",
        "ラベル ={ 0:'Tシャツ', 1:'ズボン', 2:'プルオーバー', 3:'ドレス', 4:'コート', 5:'サンダル',\n",
        "          6:'シャツ', 7:'スニーカー', 8:'バッグ', 9:'アンクルブーツ' }\n",
        "print('予測結果:', ラベル[予測結果])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ail2oBpgN1P4"
      },
      "source": [
        "**第3章**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KB1xtayROrz",
        "outputId": "992ca39c-da36-466f-8b2b-feac46c31ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               540900    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 542230 (2.07 MB)\n",
            "Trainable params: 542230 (2.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 32s 62ms/step - loss: 0.4679 - accuracy: 0.8382 - val_loss: 0.3731 - val_accuracy: 0.8656\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.3092 - accuracy: 0.8899 - val_loss: 0.2992 - val_accuracy: 0.8910\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.2673 - accuracy: 0.9042 - val_loss: 0.2856 - val_accuracy: 0.8965\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.2379 - accuracy: 0.9140 - val_loss: 0.2844 - val_accuracy: 0.8954\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.2209 - accuracy: 0.9198 - val_loss: 0.2862 - val_accuracy: 0.8934\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 25s 53ms/step - loss: 0.2006 - accuracy: 0.9261 - val_loss: 0.2688 - val_accuracy: 0.9023\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.1856 - accuracy: 0.9317 - val_loss: 0.2617 - val_accuracy: 0.9058\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.1706 - accuracy: 0.9383 - val_loss: 0.2738 - val_accuracy: 0.9012\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 25s 53ms/step - loss: 0.1577 - accuracy: 0.9425 - val_loss: 0.2495 - val_accuracy: 0.9124\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.1445 - accuracy: 0.9474 - val_loss: 0.2677 - val_accuracy: 0.9095\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.1327 - accuracy: 0.9520 - val_loss: 0.2647 - val_accuracy: 0.9094\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.1223 - accuracy: 0.9558 - val_loss: 0.2522 - val_accuracy: 0.9196\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.1115 - accuracy: 0.9599 - val_loss: 0.2606 - val_accuracy: 0.9167\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.1009 - accuracy: 0.9637 - val_loss: 0.2703 - val_accuracy: 0.9152\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0925 - accuracy: 0.9667 - val_loss: 0.2772 - val_accuracy: 0.9155\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.0841 - accuracy: 0.9708 - val_loss: 0.2812 - val_accuracy: 0.9160\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 24s 51ms/step - loss: 0.0749 - accuracy: 0.9738 - val_loss: 0.3015 - val_accuracy: 0.9122\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0666 - accuracy: 0.9767 - val_loss: 0.3094 - val_accuracy: 0.9136\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 25s 53ms/step - loss: 0.0626 - accuracy: 0.9782 - val_loss: 0.3046 - val_accuracy: 0.9220\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 25s 52ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.3290 - val_accuracy: 0.9163\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3290 - accuracy: 0.9163\n",
            "test loss: 0.329012006521225\n",
            "test acc: 0.9162999987602234\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28, 28, 1).astype(np.float32) # (2) データを前処理する\n",
        "訓練画像 /= 255 # (2) データを前処理する\n",
        "訓練ラベル = to_categorical(訓練ラベル, 10) # (3) ラベルをワンホットエンコーディングにする\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28, 28, 1).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "テストラベル = to_categorical(テストラベル, 10)\n",
        "\n",
        "model = Sequential() # (4)モデルを作成する\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu')) # 畳み込み層\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # プーリング層\n",
        "model.add(Flatten()) # 全結合層に渡すための1次元化\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax')) # 出力層\n",
        "\n",
        "model.summary() # モデルを表示する\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # (5) モデルをコンパイルする\n",
        "              optimizer='adam', # 更新方法\n",
        "              metrics=['accuracy']) # 正答率\n",
        "\n",
        "model.fit(訓練画像, 訓練ラベル, # (6) モデルを訓練する\n",
        "                 batch_size=128, epochs=20, verbose=1,\n",
        "                 validation_data=(テスト画像, テストラベル))\n",
        "\n",
        "score = model.evaluate(テスト画像, テストラベル) # (7) モデルを評価する\n",
        "print('test loss:', score[0]) # 結果の表示\n",
        "print('test acc:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで、[編集]→[ノートブックの設定]を選択し、GPUのチェックボックをクリックしてGPUに変えて以下を実行してみる"
      ],
      "metadata": {
        "id": "dqR0Gw5n8bDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28, 28, 1).astype(np.float32) # (2) データを前処理する\n",
        "訓練画像 /= 255 # (2) データを前処理する\n",
        "訓練ラベル = to_categorical(訓練ラベル, 10) # (3) ラベルをワンホットエンコーディングにする\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28, 28, 1).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "テストラベル = to_categorical(テストラベル, 10)\n",
        "\n",
        "model = Sequential() # (4)モデルを作成する\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu')) # 畳み込み層\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # プーリング層\n",
        "model.add(Flatten()) # 全結合層に渡すための1次元化\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax')) # 出力層\n",
        "\n",
        "model.summary() # モデルを表示する\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # (5) モデルをコンパイルする\n",
        "              optimizer='adam', # 更新方法\n",
        "              metrics=['accuracy']) # 正答率\n",
        "\n",
        "model.fit(訓練画像, 訓練ラベル, # (6) モデルを訓練する\n",
        "                 batch_size=128, epochs=20, verbose=1,\n",
        "                 validation_data=(テスト画像, テストラベル))\n",
        "\n",
        "score = model.evaluate(テスト画像, テストラベル) # (7) モデルを評価する\n",
        "print('test loss:', score[0]) # 結果の表示\n",
        "print('test acc:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0sfI0KV8zfS",
        "outputId": "5ad11807-dc61-47a4-b19f-8b5f93f8e82e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               540900    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 542230 (2.07 MB)\n",
            "Trainable params: 542230 (2.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 14s 15ms/step - loss: 0.4527 - accuracy: 0.8411 - val_loss: 0.3481 - val_accuracy: 0.8766\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3019 - accuracy: 0.8929 - val_loss: 0.3296 - val_accuracy: 0.8792\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2616 - accuracy: 0.9064 - val_loss: 0.2787 - val_accuracy: 0.8967\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2371 - accuracy: 0.9150 - val_loss: 0.2682 - val_accuracy: 0.9024\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2108 - accuracy: 0.9243 - val_loss: 0.2662 - val_accuracy: 0.9020\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1925 - accuracy: 0.9300 - val_loss: 0.2759 - val_accuracy: 0.9002\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1755 - accuracy: 0.9366 - val_loss: 0.2503 - val_accuracy: 0.9128\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1592 - accuracy: 0.9415 - val_loss: 0.2474 - val_accuracy: 0.9117\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1471 - accuracy: 0.9463 - val_loss: 0.2556 - val_accuracy: 0.9110\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1328 - accuracy: 0.9530 - val_loss: 0.2501 - val_accuracy: 0.9163\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1237 - accuracy: 0.9546 - val_loss: 0.2644 - val_accuracy: 0.9130\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9605 - val_loss: 0.2703 - val_accuracy: 0.9127\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0990 - accuracy: 0.9647 - val_loss: 0.2641 - val_accuracy: 0.9169\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0913 - accuracy: 0.9674 - val_loss: 0.2676 - val_accuracy: 0.9176\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0817 - accuracy: 0.9708 - val_loss: 0.2730 - val_accuracy: 0.9194\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0721 - accuracy: 0.9745 - val_loss: 0.2883 - val_accuracy: 0.9167\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0660 - accuracy: 0.9770 - val_loss: 0.3001 - val_accuracy: 0.9185\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.3043 - val_accuracy: 0.9194\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.3169 - val_accuracy: 0.9179\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.9840 - val_loss: 0.3276 - val_accuracy: 0.9177\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.9177\n",
            "test loss: 0.32761427760124207\n",
            "test acc: 0.9176999926567078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_RpMttDVHAC",
        "outputId": "330952be-e87b-4532-d6ba-edc1da62016f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               921700    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 941526 (3.59 MB)\n",
            "Trainable params: 941526 (3.59 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 7s 9ms/step - loss: 0.4293 - accuracy: 0.8471 - val_loss: 0.3491 - val_accuracy: 0.8728\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2709 - accuracy: 0.9018 - val_loss: 0.2737 - val_accuracy: 0.9010\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.2221 - accuracy: 0.9188 - val_loss: 0.2476 - val_accuracy: 0.9075\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1842 - accuracy: 0.9326 - val_loss: 0.2353 - val_accuracy: 0.9193\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1544 - accuracy: 0.9432 - val_loss: 0.2290 - val_accuracy: 0.9175\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1294 - accuracy: 0.9527 - val_loss: 0.2303 - val_accuracy: 0.9238\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1083 - accuracy: 0.9609 - val_loss: 0.2490 - val_accuracy: 0.9191\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0852 - accuracy: 0.9692 - val_loss: 0.2350 - val_accuracy: 0.9265\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0702 - accuracy: 0.9748 - val_loss: 0.2803 - val_accuracy: 0.9190\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0557 - accuracy: 0.9798 - val_loss: 0.2912 - val_accuracy: 0.9235\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.3189 - val_accuracy: 0.9222\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0372 - accuracy: 0.9868 - val_loss: 0.3343 - val_accuracy: 0.9220\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 0.3697 - val_accuracy: 0.9216\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.3752 - val_accuracy: 0.9224\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.4125 - val_accuracy: 0.9227\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.4762 - val_accuracy: 0.9163\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.4598 - val_accuracy: 0.9235\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.4742 - val_accuracy: 0.9214\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.4687 - val_accuracy: 0.9205\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.5018 - val_accuracy: 0.9215\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.9215\n",
            "test loss: 0.5017726421356201\n",
            "test acc: 0.921500027179718\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28, 28, 1).astype(np.float32) # (2) データを前処理する\n",
        "訓練画像 /= 255 # (2)  データを前処理する\n",
        "訓練ラベル = to_categorical(訓練ラベル, 10) # (3) ラベルをワンホットエンコーディングにする\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28, 28, 1).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "テストラベル = to_categorical(テストラベル, 10)\n",
        "\n",
        "model = Sequential() # (4)モデルを作成する\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu')) # 畳み込み層\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) # 畳み込み層\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # プーリング層\n",
        "model.add(Flatten()) # 全結合層に渡すための1次元化\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax')) # 出力層\n",
        "\n",
        "model.summary() # モデルを表示する\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # (5) モデルをコンパイルする\n",
        "              optimizer='adam', # 更新方法\n",
        "              metrics=['accuracy']) # 正答率\n",
        "\n",
        "model.fit(訓練画像, 訓練ラベル, # (6) モデルを訓練する\n",
        "                 batch_size=128, epochs=20, verbose=1,\n",
        "                 validation_data=(テスト画像, テストラベル))\n",
        "\n",
        "score = model.evaluate(テスト画像, テストラベル) # (7) モデルを評価する\n",
        "print('test loss:', score[0]) # 結果の表示\n",
        "print('test acc:', score[1])\n",
        "\n",
        "model.save('model_weightsCNN.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NQsOG6KaaOEN",
        "outputId": "8e931f9d-51e5-422c-c20f-6633ba0d6226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 129ms/step\n",
            "[[1.2981104e-12 1.9100892e-19 8.7993495e-17 1.6026815e-18 2.7217771e-16\n",
            "  1.2489311e-19 1.7411004e-12 2.0601264e-14 1.0000000e+00 1.7446974e-12]]\n",
            "予測結果: バッグ\n"
          ]
        }
      ],
      "source": [
        "! curl -s -O http://matsuda.php.xdomain.jp/pe/bag.jpg\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('model_weightsCNN.keras') # 訓練結果の読み込み\n",
        "\n",
        "画像 = cv2.imread('bag.jpg') # 画像ファイルの読み込み\n",
        "画像 = cv2.resize(画像, (28, 28)) #データのリサイズ\n",
        "グレー画像 = cv2.cvtColor(画像, cv2.COLOR_BGR2GRAY) # グレースケール化\n",
        "白黒反転 = cv2.bitwise_not(グレー画像) # 白黒反転する\n",
        "白黒反転 = np.array(白黒反転, 'float32') # NumPyの配列にする\n",
        "自分の画像 = 白黒反転.reshape(1, 28, 28, 1) # 2次元配列に変換\n",
        "自分の画像 /= 255  # 0~1へ\n",
        "\n",
        "予測結果群 = model.predict([自分の画像]) # 分類\n",
        "print(予測結果群)\n",
        "予測結果 = np.argmax(予測結果群)\n",
        "ラベル ={ 0:'Tシャツ', 1:'ズボン', 2:'プルオーバー', 3:'ドレス', 4:'コート', 5:'サンダル',\n",
        "          6:'シャツ', 7:'スニーカー', 8:'バッグ', 9:'アンクルブーツ' }\n",
        "print('予測結果:', ラベル[予測結果])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXOENMN__Seq"
      },
      "source": [
        "**第4章**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "phLY8fk1Qrx_",
        "outputId": "a24db705-b8ae-4b04-cee0-c7e4b3b6813e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2400 files belonging to 3 classes.\n",
            "['Bag', 'Boot', 'Sneaker']\n"
          ]
        }
      ],
      "source": [
        "! curl -s -O http://matsuda.php.xdomain.jp/pe/data.zip\n",
        "! unzip -q -o data.zip\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "訓練データセット = image_dataset_from_directory(\n",
        "    'data/train',\n",
        "    label_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    image_size=(28, 28),\n",
        "    batch_size=128,\n",
        ")\n",
        "\n",
        "print(訓練データセット.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DdQkU9ogbROT",
        "outputId": "3c78ee84-ba67-40a6-998f-c3a7deb84ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2400 files belonging to 3 classes.\n",
            "['Bag', 'Boot', 'Sneaker']\n",
            "Found 600 files belonging to 3 classes.\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - 2s 26ms/step - loss: 0.3425 - accuracy: 0.8867 - val_loss: 0.1973 - val_accuracy: 0.9300\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.1491 - accuracy: 0.9521 - val_loss: 0.1218 - val_accuracy: 0.9550\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 0.1134 - accuracy: 0.9588 - val_loss: 0.1146 - val_accuracy: 0.9650\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 0.1059 - accuracy: 0.9638 - val_loss: 0.0990 - val_accuracy: 0.9583\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0912 - accuracy: 0.9671 - val_loss: 0.0909 - val_accuracy: 0.9667\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 1s 21ms/step - loss: 0.0811 - accuracy: 0.9700 - val_loss: 0.0866 - val_accuracy: 0.9667\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0806 - accuracy: 0.9717 - val_loss: 0.1035 - val_accuracy: 0.9667\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 1s 21ms/step - loss: 0.0706 - accuracy: 0.9754 - val_loss: 0.0977 - val_accuracy: 0.9683\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 0.0819 - val_accuracy: 0.9700\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0634 - accuracy: 0.9771 - val_loss: 0.0880 - val_accuracy: 0.9700\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0616 - accuracy: 0.9800 - val_loss: 0.0754 - val_accuracy: 0.9733\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0552 - accuracy: 0.9821 - val_loss: 0.0735 - val_accuracy: 0.9750\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 0.0531 - accuracy: 0.9796 - val_loss: 0.0775 - val_accuracy: 0.9750\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0500 - accuracy: 0.9829 - val_loss: 0.0804 - val_accuracy: 0.9733\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0458 - accuracy: 0.9837 - val_loss: 0.0841 - val_accuracy: 0.9733\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0516 - accuracy: 0.9825 - val_loss: 0.0866 - val_accuracy: 0.9700\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0462 - accuracy: 0.9837 - val_loss: 0.0781 - val_accuracy: 0.9750\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.0725 - val_accuracy: 0.9750\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 1s 21ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.0763 - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 1s 21ms/step - loss: 0.0361 - accuracy: 0.9883 - val_loss: 0.0843 - val_accuracy: 0.9667\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9667\n",
            "test loss: 0.0843452513217926\n",
            "test acc: 0.9666666388511658\n"
          ]
        }
      ],
      "source": [
        "! curl -s -O http://matsuda.php.xdomain.jp/pe/data.zip\n",
        "! unzip -q -o data.zip\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Rescaling\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "訓練データセット = image_dataset_from_directory(\n",
        "    'data/train',\n",
        "    label_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    image_size=(28, 28),\n",
        "    batch_size=128,\n",
        ")\n",
        "print(訓練データセット.class_names)\n",
        "テストデータセット = image_dataset_from_directory(\n",
        "    'data/test',\n",
        "    label_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    image_size=(28, 28),\n",
        "    batch_size=128,\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Rescaling(1./255))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    訓練データセット,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        "    validation_data=テストデータセット\n",
        ")\n",
        "\n",
        "score = model.evaluate(テストデータセット)\n",
        "print('test loss:', score[0])\n",
        "print('test acc:', score[1])\n",
        "\n",
        "model.save('model_weightsCNN.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N_rheRO0-far",
        "outputId": "bea6fc62-d88c-45f7-dd0d-0ef0745f6dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "[[1.0000000e+00 2.3491334e-10 9.6827624e-12]]\n",
            "Bag\n"
          ]
        }
      ],
      "source": [
        "! curl -s -O http://matsuda.php.xdomain.jp/pe/bag.jpg\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('model_weightsCNN.keras')\n",
        "\n",
        "画像 = cv2.imread('bag.jpg') # 画像ファイルの読み込み\n",
        "画像 = cv2.resize(画像, (28, 28)) #データのリサイズ\n",
        "グレー画像 = cv2.cvtColor(画像, cv2.COLOR_BGR2GRAY) # グレースケール化\n",
        "白黒反転 = cv2.bitwise_not(グレー画像) # 白黒反転する\n",
        "白黒反転 = np.array(白黒反転, 'float32') # NumPyの配列にする\n",
        "自分の画像 = 白黒反転.reshape(1, 28, 28, 1) # 2次元配列に変換\n",
        "# 自分の画像 /= 255  # 0~1へ\n",
        "\n",
        "予測結果群 = model.predict([自分の画像]) # 分類\n",
        "print(予測結果群)\n",
        "予測結果 = np.argmax(予測結果群)\n",
        "クラス名 = ['Bag', 'Boot', 'Sneaker']\n",
        "print(クラス名[予測結果])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TVDKe8pMAXHM",
        "outputId": "1354a749-f300-4ce8-af86-93a9cc15b787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3000 files belonging to 3 classes.\n",
            "Using 2400 files for training.\n",
            "['Bag', 'Boot', 'Sneaker']\n",
            "Found 3000 files belonging to 3 classes.\n",
            "Using 600 files for validation.\n"
          ]
        }
      ],
      "source": [
        "! curl -s -O http://matsuda.php.xdomain.jp/pe/data2.zip\n",
        "! unzip -q -o data2.zip\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "訓練データセット = image_dataset_from_directory(\n",
        "    'data2',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=123,\n",
        "    label_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    image_size=(28, 28),\n",
        "    batch_size=128,\n",
        ")\n",
        "print(訓練データセット.class_names)\n",
        "テストデータセット = image_dataset_from_directory(\n",
        "    'data2',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=123,\n",
        "    label_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    image_size=(28, 28),\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJWX65GCZW_m",
        "outputId": "e90023ff-b46f-4386-bdd0-faf6e94f0925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 12, 12, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               921700    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 941526 (3.59 MB)\n",
            "Trainable params: 941526 (3.59 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 8ms/step - loss: 0.4373 - accuracy: 0.8440 - val_loss: 0.3455 - val_accuracy: 0.8797\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.2684 - accuracy: 0.9034 - val_loss: 0.2741 - val_accuracy: 0.9011\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.2172 - accuracy: 0.9216 - val_loss: 0.2421 - val_accuracy: 0.9136\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1804 - accuracy: 0.9353 - val_loss: 0.2423 - val_accuracy: 0.9096\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1534 - accuracy: 0.9434 - val_loss: 0.2265 - val_accuracy: 0.9188\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1267 - accuracy: 0.9532 - val_loss: 0.2356 - val_accuracy: 0.9179\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1034 - accuracy: 0.9620 - val_loss: 0.2488 - val_accuracy: 0.9217\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0820 - accuracy: 0.9699 - val_loss: 0.2551 - val_accuracy: 0.9231\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0662 - accuracy: 0.9759 - val_loss: 0.2715 - val_accuracy: 0.9237\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.2914 - val_accuracy: 0.9241\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[858   1  20   6   3   0 105   0   7   0]\n",
            " [  1 986   0   6   0   0   5   0   2   0]\n",
            " [ 15   1 870   6  50   0  57   0   1   0]\n",
            " [ 12   8  15 878  31   1  52   0   3   0]\n",
            " [  0   0  25  14 916   0  44   0   1   0]\n",
            " [  0   0   0   0   1 983   0  10   0   6]\n",
            " [ 69   0  35  12  56   0 821   0   7   0]\n",
            " [  0   0   0   0   0   5   0 982   0  13]\n",
            " [  1   1   0   5   2   1   5   1 984   0]\n",
            " [  0   0   0   0   0   5   1  31   0 963]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "訓練データ, テストデータ = fashion_mnist.load_data() # (1) データセットを読み込む\n",
        "訓練画像, 訓練ラベル = 訓練データ\n",
        "テスト画像, テストラベル = テストデータ\n",
        "\n",
        "訓練画像 = 訓練画像.reshape(len(訓練画像), 28, 28, 1).astype(np.float32) # 画像を1次元にする\n",
        "訓練画像 /= 255 # (2) (2) データを前処理する\n",
        "訓練ラベル = to_categorical(訓練ラベル, 10) # (3) ラベルをワンホットエンコーディングにする\n",
        "テスト画像 = テスト画像.reshape(len(テスト画像), 28, 28, 1).astype(np.float32)\n",
        "テスト画像 /= 255\n",
        "テストラベル = to_categorical(テストラベル, 10)\n",
        "\n",
        "model = Sequential() # (4)モデルを作成する\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu')) # 畳み込み層\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) # 畳み込み層\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # プーリング層\n",
        "model.add(Flatten()) # 全結合層に渡すための1次元化\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax')) # 出力層\n",
        "\n",
        "model.summary() # モデルを表示する\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', # (5) モデルをコンパイルする\n",
        "              optimizer='adam', # 更新方法\n",
        "              metrics=['accuracy']) # 正答率\n",
        "\n",
        "model.fit(訓練画像, 訓練ラベル, # (6) モデルを訓練する\n",
        "                 batch_size=128, epochs=10, verbose=1,\n",
        "                 validation_data=(テスト画像, テストラベル))\n",
        "\n",
        "from sklearn import metrics # 間違った画像の確認\n",
        "予測結果 = model.predict(テスト画像) # (7) モデルを評価する\n",
        "予測結果 = np.argmax(予測結果, axis=1)\n",
        "テストラベル = np.argmax(テストラベル, axis=1)\n",
        "print(metrics.confusion_matrix(テストラベル, 予測結果))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HAtnfWo9ImG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ec0074-e62c-4134-e580-85683ea01823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138357544 (527.79 MB)\n",
            "Trainable params: 138357544 (527.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "model = VGG16(weights='imagenet') # 事前学習済みのVGG16の読み込み\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOCRIcT2ZZw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61522c0-df9e-407a-8243-df7dfaba84b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 5s 0us/step\n",
            "1/1 [==============================] - 8s 8s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "('n02504013', 'Indian_elephant', 0.78464866)\n",
            "('n01871265', 'tusker', 0.20018817)\n",
            "('n02504458', 'African_elephant', 0.015160673)\n",
            "('n01704323', 'triceratops', 8.6753914e-07)\n",
            "('n02480855', 'gorilla', 6.3235484e-07)\n"
          ]
        }
      ],
      "source": [
        "! curl -s -O http://matsuda.php.xdomain.jp/pe/elephant.png\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "import cv2\n",
        "\n",
        "model = VGG16(weights='imagenet') # 学習済みのVGG16の読み込み\n",
        "# model.summary()\n",
        "\n",
        "画像 = cv2.imread('elephant.png') # 画像データの読み込み\n",
        "画像 = cv2.resize(画像, (224, 224)) #データのリサイズ\n",
        "画像 = preprocess_input(画像) # 画像の前処理\n",
        "画像 = 画像.reshape(1, 224, 224, 3) # 224x224×3(カラー)の配列に変換\n",
        "\n",
        "予測結果 = model.predict([画像]) # 予測\n",
        "top5 = decode_predictions(予測結果, top=5)[0] # Top-5のクラスを表示\n",
        "for r in top5: # VGG16の1000クラスはdecode_predictions()で文字列に\n",
        "    print(r)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}