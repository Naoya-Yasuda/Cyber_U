{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第14回演習「バンディットアルゴリズム」その2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) まずここを実行しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "回数毎の平均報酬=[]\n",
    "回数毎の累積報酬=[]\n",
    "一回のシミュレーションで引く回数=250\n",
    "シミュレーションの回数=3000\n",
    "乱数発生器 = np.random.RandomState(3)\n",
    "#乱数発生器 = np.random\n",
    "\n",
    "class アーム():\n",
    "    def __init__(self,確率):\n",
    "        self.確率=確率\n",
    "        self.引いた回数=0\n",
    "        self.平均報酬=0\n",
    "    def アームの初期化(self):\n",
    "        self.引いた回数=0\n",
    "        self.平均報酬=0        \n",
    "    def 平均報酬を更新(self,この報酬):\n",
    "        n=self.引いた回数\n",
    "        self.平均報酬=((n-1)*self.平均報酬+この報酬)/n        \n",
    "    def 引く(self):\n",
    "        乱数_0から1まで = 乱数発生器.uniform(0, 1)\n",
    "        if 乱数_0から1まで <= self.確率:\n",
    "            この報酬=1\n",
    "        else:\n",
    "            この報酬=0\n",
    "        self.引いた回数=self.引いた回数+1\n",
    "        self.平均報酬を更新(この報酬)\n",
    "        return この報酬\n",
    "\n",
    "アーム1=アーム(0.1)\n",
    "アーム2=アーム(0.1)\n",
    "アーム3=アーム(0.1)\n",
    "アーム4=アーム(0.1)\n",
    "アーム5=アーム(0.9)\n",
    "アームの配列=[アーム1,アーム2,アーム3,アーム4,アーム5]\n",
    "\n",
    "def 平均報酬最大のアームのインデックスを知る(アームの配列):\n",
    "    暫定最大値 = -1\n",
    "    暫定最大インデックスの配列=[]\n",
    "    for このアームのインデックス in range(len(アームの配列)):\n",
    "        if アームの配列[このアームのインデックス].平均報酬 > 暫定最大値:\n",
    "            暫定最大値=アームの配列[このアームのインデックス].平均報酬\n",
    "            暫定最大インデックスの配列=[このアームのインデックス]\n",
    "        elif アームの配列[このアームのインデックス].平均報酬 == 暫定最大値:\n",
    "            暫定最大インデックスの配列.append(このアームのインデックス)\n",
    "    return 乱数発生器.choice(暫定最大インデックスの配列)\n",
    "\n",
    "def εグリーディ法でアームを決定(ランダム行動の選択率ε,アームの配列):\n",
    "    乱数_0から1まで = 乱数発生器.uniform(0, 1)\n",
    "    # 乱数がε以上なら、平均報酬最大のアームを選択    \n",
    "    if ランダム行動の選択率ε <= 乱数_0から1まで:\n",
    "        平均報酬最大のインデックス=平均報酬最大のアームのインデックスを知る(アームの配列)\n",
    "        return 平均報酬最大のインデックス\n",
    "    # 乱数がε未満なら、ランダムなアーム\n",
    "    else:\n",
    "        return 乱数発生器.randint(len(アームの配列))\n",
    "    \n",
    "def εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,ランダム行動の選択率ε):\n",
    "    global 回数毎の平均報酬 # グローバル変数を弄るので\n",
    "    global 回数毎の累積報酬 # グローバル変数を弄るので\n",
    "    回数毎の平均報酬=[]\n",
    "    回数毎の累積報酬=[]\n",
    "    \n",
    "    for 回数 in range(一回のシミュレーションで引く回数):\n",
    "        回数毎の平均報酬.append([]) # 空にする\n",
    "        回数毎の累積報酬.append([]) # 空にする        \n",
    "\n",
    "    for このシミュレーション in range(シミュレーションの回数):\n",
    "        このシミュレーションの報酬総額=0\n",
    "        for このアーム in アームの配列:        \n",
    "            このアーム.アームの初期化()\n",
    "\n",
    "        #print(\"==========================================\")\n",
    "        #print(\"解の番号, 引いたアームのインデックス, 得た報酬, このアームを引いた回数, このアームの平均報酬, このシミュレーション内の平均報酬\")                \n",
    "        for この回 in range(一回のシミュレーションで引く回数):            \n",
    "            決めたアームのインデックス=εグリーディ法でアームを決定(ランダム行動の選択率ε,アームの配列)\n",
    "            このアーム=アームの配列[決めたアームのインデックス]\n",
    "            得た報酬=このアーム.引く()\n",
    "            このシミュレーションの報酬総額=このシミュレーションの報酬総額+得た報酬\n",
    "            このシミュレーションの平均報酬=このシミュレーションの報酬総額/(この回+1)        \n",
    "            #print(この回,\"\",end=\"\")\n",
    "            #print(決めたアームのインデックス,end=\"\")            \n",
    "            #print(\"\",得た報酬,このアーム.引いた回数,このアーム.平均報酬,end=\"\")\n",
    "            #print(\"\",このシミュレーションの平均報酬)            \n",
    "            回数毎の平均報酬[この回].append(このシミュレーションの平均報酬)\n",
    "            回数毎の累積報酬[この回].append(このシミュレーションの報酬総額)\n",
    "        #print(\"解の番号, 引いたアームのインデックス, 得た報酬, このアームを引いた回数, このアームの平均報酬, このシミュレーション内の平均報酬\")                        \n",
    "\n",
    "print(\"#6 を実行しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) ε=0.5として「250回のアーム選択」を<br />3000回シミュレーションし、回数毎の平均報酬を<br />テキストとして出力<br />【注】 5～10秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 回数毎の平均報酬をテキストとして表示(一回のシミュレーションで引く回数):\n",
    "    for 回数 in range(一回のシミュレーションで引く回数):\n",
    "        print(回数,np.mean(回数毎の平均報酬[回数]))\n",
    "\n",
    "一回のシミュレーションで引く回数=250\n",
    "シミュレーションの回数=3000        \n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をテキストとして表示(一回のシミュレーションで引く回数)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題6) \n",
    "<span style=\"background-color:#FFFF99\">上記#6を2~3回実行して250回目の平均報酬のブレが許容範囲内であることを確認しましょう。</span><br />【注】 5～10秒程度、待たされます<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をテキストとして表示(一回のシミュレーションで引く回数)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) εを0.5で「250回のアーム選択」を3000回シミュレーションし、回数毎の平均報酬を図示<br />【注】 5～10秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 回数毎の平均報酬をプロット(ラベル,一回のシミュレーションで引く回数):\n",
    "    図示用のY=[]\n",
    "    for 回数 in range(一回のシミュレーションで引く回数):\n",
    "        図示用のY.append(np.mean(回数毎の平均報酬[回数]))\n",
    "    plt.plot(図示用のY,label=ラベル)\n",
    "    \n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) εを0.1⇒0.3⇒0.5と変えながら「250回のアーム選択」をそれぞれ3000回シミュレーションし、回数毎の平均報酬を図示<br />【注】 それぞれ5～10秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε=0.1\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.1)\n",
    "回数毎の平均報酬をプロット(0.1,一回のシミュレーションで引く回数)\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε=0.3\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.3)\n",
    "回数毎の平均報酬をプロット(0.3,一回のシミュレーションで引く回数)\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε=0.5\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) プログラム#9の3つの結果を重ねてプロットし、<br />凡例もつける<br />【注】 全体で20秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.1)\n",
    "回数毎の平均報酬をプロット(0.1,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.3)\n",
    "回数毎の平均報酬をプロット(0.3,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) εを0.1⇒0.3⇒0.5と変え、回数毎の累積報酬を図示<br />【注】 全体で20秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 回数毎の累積報酬をプロット(ラベル,一回のシミュレーションで引く回数):\n",
    "    図示用のY=[]\n",
    "    for 回数 in range(一回のシミュレーションで引く回数):\n",
    "        図示用のY.append(np.mean(回数毎の累積報酬[回数]))\n",
    "    plt.plot(図示用のY,label=ラベル)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.1)\n",
    "回数毎の累積報酬をプロット(0.1,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.3)\n",
    "回数毎の累積報酬をプロット(0.3,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の累積報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) ε=0 での平均報酬を図示し、<br />0.1⇒0.3⇒0.5の平均報酬の図に重ねる<br />【注】 全体で20秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.1)\n",
    "回数毎の平均報酬をプロット(0.1,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.3)\n",
    "回数毎の平均報酬をプロット(0.3,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0) # εは0\n",
    "回数毎の平均報酬をプロット(0,一回のシミュレーションで引く回数)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題7) \n",
    "<span style=\"background-color:#FFFF99\">ε=0がε=0.1に平均報酬で抜かれたのはなぜか、考えましょう。</span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) プログラム#12と同様、ε=1を試して図示<br />【注】 全体で20秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.1)\n",
    "回数毎の平均報酬をプロット(0.1,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.3)\n",
    "回数毎の平均報酬をプロット(0.3,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0) # εは0\n",
    "回数毎の平均報酬をプロット(0,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,1) # εは1\n",
    "回数毎の平均報酬をプロット(1,一回のシミュレーションで引く回数)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) εを0.5から徐々に減らすようにアニールさせ、<br />回数毎の平均報酬を図示<br />【注】 全体で20秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def アニールするεグリーディ法でアームを決定(ランダム行動の選択率ε,アームの配列,回数):\n",
    "    ランダム行動の選択率ε = ランダム行動の選択率ε*(1/(回数+1)) # 引く回数が増えるとεが減る\n",
    "    乱数_0から1まで = 乱数発生器.uniform(0, 1)\n",
    "    # 乱数がε以上なら、平均報酬最大のアームを選択    \n",
    "    if ランダム行動の選択率ε <= 乱数_0から1まで:\n",
    "        平均報酬最大のインデックス=平均報酬最大のアームのインデックスを知る(アームの配列)\n",
    "        return 平均報酬最大のインデックス\n",
    "    # 乱数がε未満なら、ランダムなアーム\n",
    "    else:\n",
    "        return 乱数発生器.randint(len(アームの配列))\n",
    "\n",
    "def アニールするεグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,ランダム行動の選択率ε):\n",
    "    global 回数毎の平均報酬 # グローバル変数を弄るので    \n",
    "    回数毎の平均報酬=[]\n",
    "    \n",
    "    for 回数 in range(一回のシミュレーションで引く回数):\n",
    "        回数毎の平均報酬.append([]) # 空にする\n",
    "\n",
    "    for このシミュレーション in range(シミュレーションの回数):\n",
    "        このシミュレーションの報酬総額=0\n",
    "        for このアーム in アームの配列:        \n",
    "            このアーム.アームの初期化()\n",
    "                    \n",
    "        for この回 in range(一回のシミュレーションで引く回数):\n",
    "            決めたアームのインデックス=アニールするεグリーディ法でアームを決定(ランダム行動の選択率ε,アームの配列,この回)\n",
    "            このアーム=アームの配列[決めたアームのインデックス]\n",
    "            得た報酬=このアーム.引く()\n",
    "            このシミュレーションの報酬総額=このシミュレーションの報酬総額+得た報酬\n",
    "            このシミュレーションの平均報酬=このシミュレーションの報酬総額/(この回+1)\n",
    "            回数毎の平均報酬[この回].append(このシミュレーションの平均報酬)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.1)\n",
    "回数毎の平均報酬をプロット(0.1,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.3)\n",
    "回数毎の平均報酬をプロット(0.3,一回のシミュレーションで引く回数)\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "\n",
    "アニールするεグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(\"anneal-0.5\",一回のシミュレーションで引く回数)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# ↓待たされます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題8) \n",
    "<span style=\"background-color:#FFFF99\">アニールの式を変えてみましょう。<br />εをどのように減らしていくか、アイディアを出して結果を確かめましょう。</span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) アームの当たる確率を変更して回数毎の平均報酬を図示<br />【注】 全体で20秒程度、待たされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "アーム1=アーム(0.6)\n",
    "アーム2=アーム(0.6)\n",
    "アーム3=アーム(0.6)\n",
    "アーム4=アーム(0.6)\n",
    "アーム5=アーム(0.9)\n",
    "アームの配列=[アーム1,アーム2,アーム3,アーム4,アーム5]\n",
    "\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.1)\n",
    "回数毎の平均報酬をプロット(0.1,一回のシミュレーションで引く回数)\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.3)\n",
    "回数毎の平均報酬をプロット(0.3,一回のシミュレーションで引く回数)\n",
    "εグリーディ法でシミュレーション(アームの配列,一回のシミュレーションで引く回数,シミュレーションの回数,0.5)\n",
    "回数毎の平均報酬をプロット(0.5,一回のシミュレーションで引く回数)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小出しの任意課題9) \n",
    "<span style=\"background-color:#FFFF99\">プログラム #15 で、各アームの当たる確率を好みの値に変えて実行してみましょう。</span><hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第14回第4章の演習はここまでです。お疲れさまでした。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
